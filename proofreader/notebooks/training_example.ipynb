{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from proofreader.utils.vis import plot_3d\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from proofreader.data.cremi import prepare_cremi_vols\n",
    "\n",
    "train_vols, test_vols = prepare_cremi_vols('../../dataset/cremi')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from proofreader.data.splitter import NeuriteDataset\n",
    "from proofreader.data.augment import Augmentor\n",
    "num_slices = [4, 4]\n",
    "radius = 96\n",
    "context_slices = 4\n",
    "num_points = 1024\n",
    "\n",
    "augmentor = Augmentor(center=True, shuffle=True, normalize=[125, 1250, 1250])\n",
    "train_dataset = NeuriteDataset(test_vols, num_slices, radius, context_slices, num_points=num_points, torch=True, open_vol=True, verbose=False, Augmentor=augmentor)\n",
    "print(len(train_dataset))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "config = get_config('cn_context_4_aug_small')\n",
    "dataloader = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True)\n",
    "model, _ ,_ = build_full_model_from_config(config.model, config.dataset)\n",
    "model = nn.DataParallel(model)\n",
    "model = load_model(model, '../../330.ckpt', map_location=torch.device('cpu'))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from proofreader.model.classifier import *\n",
    "with torch.no_grad():\n",
    "    count, acc = 0,0\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        count += 1\n",
    "        # get batch\n",
    "        x, y = batch\n",
    "        y_hat = model(x)\n",
    "        pred = predict_class(y_hat)\n",
    "        accs = get_accuracy(y, pred)\n",
    "        print(accs)\n",
    "        acc += accs['total_acc']\n",
    "        print(round(acc/count, 3))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from proofreader.utils.data import *\n",
    "from proofreader.utils.all import *\n",
    "from proofreader.utils.vis import *\n",
    "import cc3d\n",
    "from skimage.segmentation import find_boundaries\n",
    "from scipy import ndimage\n",
    "from proofreader.utils.torch import *\n",
    "from proofreader.data.augment import Augmentor\n",
    "\n",
    "class TestDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self,\n",
    "                 vols,\n",
    "                 num_slices: int,\n",
    "                 radius: int,\n",
    "                 context_slices: int,\n",
    "                 num_points: int = None,\n",
    "                 add_batch_id: bool = False,\n",
    "                 Augmentor: Augmentor = Augmentor(),\n",
    "                 verbose: bool = False,\n",
    "                 ):\n",
    "\n",
    "        # clean vols\n",
    "        self.vols = []\n",
    "        for vol in vols:\n",
    "            vol = zero_classes_with_min_volume(vol, 500)\n",
    "            self.vols.append(vol)\n",
    "\n",
    "        self.num_slices = num_slices\n",
    "        self.radius = radius\n",
    "        self.context_slices = context_slices\n",
    "        self.num_points = num_points\n",
    "        self.Augmentor = Augmentor\n",
    "        self.verbose = verbose\n",
    "        self.add_batch_id = add_batch_id\n",
    "\n",
    "        self.test_iteration_batch = None\n",
    "        self.test_iteration_i = 0\n",
    "        self.test_iteration_len = 0\n",
    "\n",
    "        self.top_neurites = np.zeros((0))\n",
    "        self.cur_neurite_i = 0\n",
    "        self.vol_relabeled = None\n",
    "        self.label_map = None\n",
    "\n",
    "        self.cur_drop_start = context_slices\n",
    "        self.cur_vol_i = 0\n",
    "\n",
    "        self.no_true = 0\n",
    "        self.multi_true = 0\n",
    "\n",
    "\n",
    "    def load_next_candidate_batch(self):\n",
    "        \n",
    "        if self.cur_neurite_i >= self.top_neurites.shape[0]:\n",
    "            if self.verbose:\n",
    "                print('getting all top neurites for drop')\n",
    "\n",
    "            # only increment if its not the init\n",
    "            if self.top_neurites.shape[0] > 0:\n",
    "                self.increment_vol_and_drop()\n",
    "\n",
    "            vol = self.get_cur_vol()\n",
    "            (drop_start, drop_end) = self.get_cur_drop()\n",
    "            cs = self.context_slices\n",
    "\n",
    "            # build a new vol with slices dropped in the middle\n",
    "            # and do connected_components do relablel/detach neurites on\n",
    "            # either side of the volume\n",
    "            vol_relabeled = np.zeros_like(vol)\n",
    "            vol_relabeled[drop_start -\n",
    "                          cs:drop_start] = vol[drop_start-cs:drop_start]\n",
    "            vol_relabeled[drop_end:drop_end+cs] = vol[drop_end:drop_end+cs]\n",
    "\n",
    "            # remeber where the background is then reset in after cc\n",
    "            zero_indices = vol_relabeled == 0\n",
    "            vol_relabeled = cc3d.connected_components(vol_relabeled)\n",
    "            vol_relabeled[zero_indices] = 0\n",
    "\n",
    "            # create a map from the new lables to the original labels\n",
    "            # this allows us to figure out the ground truth for accuracy\n",
    "            label_map = correspond_labels(vol_relabeled, vol, bg_label=0)\n",
    "\n",
    "            # take the neurites on the top border of the missing slices\n",
    "            # and attempt to reattach\n",
    "            top_neurites = np.unique(vol_relabeled[drop_start-1])\n",
    "            top_neurites = np.delete(top_neurites, 0)\n",
    "            np.random.shuffle(top_neurites)\n",
    "            self.top_neurites = top_neurites\n",
    "            self.cur_neurite_i = 0\n",
    "            self.vol_relabeled = vol_relabeled\n",
    "            self.label_map = label_map\n",
    "\n",
    "        drop = self.get_cur_drop()\n",
    "        c = self.top_neurites[self.cur_neurite_i]\n",
    "\n",
    "        examples, labels = self.get_examples_from_top_class(\n",
    "            self.vol_relabeled, c, drop, self.label_map)\n",
    "\n",
    "        # # sanity check\n",
    "        num_true = labels.count_nonzero()\n",
    "        if num_true == 0:\n",
    "            self.no_true += 1\n",
    "        if num_true > 1:\n",
    "            self.multi_true += 1\n",
    "\n",
    "        self.cur_neurite_i += 1\n",
    "\n",
    "        print()\n",
    "        return (examples, labels)\n",
    "\n",
    "    def get_examples_from_top_class(self, vol, c, drop, label_map):\n",
    "\n",
    "        top_c = c\n",
    "        (sz, sy, sx) = vol.shape\n",
    "\n",
    "        # Find min and max z slice on which c occurs #\n",
    "        for i in range(sz):\n",
    "            if c in vol[i]:\n",
    "                zmin = i\n",
    "                break\n",
    "\n",
    "        drop_start, drop_end = drop\n",
    "        num_slices = drop_end - drop_start\n",
    "        top_z_len = min(self.context_slices, drop_start-zmin)\n",
    "        bot_z_len = min(self.context_slices, sz-drop_end)\n",
    "\n",
    "        # Alloc final vol, we dont know how large it will be in y and x but we know max z #\n",
    "        mz = num_slices + top_z_len + bot_z_len\n",
    "        final_vol = np.zeros((mz, sy, sx), dtype='uint')\n",
    "\n",
    "        # Build top section #\n",
    "        top_vol_section = final_vol[0:top_z_len]\n",
    "        top_vol_section[vol[drop_start-top_z_len:drop_start] == top_c] = top_c\n",
    "\n",
    "        # Get midpoint of neurite on 2D top cross section, #\n",
    "        top_border = top_vol_section[-1]\n",
    "        # use the relabeled top section\n",
    "        (com_x, com_y) = ndimage.measurements.center_of_mass(top_border)\n",
    "        (com_x, com_y) = round(com_x), round(com_y)\n",
    "\n",
    "        # Find all neurites with distnce D from that point on bottom cross section #\n",
    "        bot_border = vol[drop_end].copy()  # need copy because we zero\n",
    "        mask = circular_mask(\n",
    "            bot_border.shape[0], bot_border.shape[1], center=(com_y, com_x), radius=self.radius)\n",
    "        bot_border[~mask] = 0\n",
    "\n",
    "        # get classes in order of distance from top neurite\n",
    "        # for efficieny we just look at the top_border and bot_border stack\n",
    "        # with mask already applied to bot_border\n",
    "        d_vol = np.stack([top_border, bot_border])\n",
    "        d_vol = crop_where(d_vol, d_vol != 0)\n",
    "        mismatch_classes = get_classes_sorted_by_distance(d_vol, top_c, method='mean')\n",
    "\n",
    "        final_vol[0: top_z_len] = top_vol_section\n",
    "        final_examples = torch.zeros(\n",
    "            (len(mismatch_classes), 3, self.num_points))\n",
    "        final_lables = []\n",
    "        for i, bot_c in enumerate(mismatch_classes):\n",
    "\n",
    "            cur_vol = final_vol.copy()\n",
    "            # Build bot section #\n",
    "            bot_vol_section = cur_vol[num_slices+top_z_len:]\n",
    "            bot_vol_section[vol[drop_end:drop_end+bot_z_len] == bot_c] = bot_c\n",
    "\n",
    "            # Build final volume of bottom sections #\n",
    "            cur_vol[num_slices+top_z_len:] = bot_vol_section\n",
    "\n",
    "            pc = self.convert_volumetric_to_final(cur_vol)\n",
    "            final_examples[i] = pc\n",
    "            label = int(label_map[top_c] == label_map[bot_c])\n",
    "            final_lables.append(label)\n",
    "\n",
    "        return final_examples, torch.tensor(final_lables)\n",
    "\n",
    "    def remove_vol_interiors(self, vol):\n",
    "\n",
    "        def rm_interior(v):\n",
    "            return v * find_boundaries(\n",
    "                v, mode='inner')\n",
    "\n",
    "        for i in range(vol.shape[0]):\n",
    "            vol[i] = rm_interior(vol[i])\n",
    "\n",
    "        return vol\n",
    "\n",
    "    def convert_to_point_cloud(self, vol):\n",
    "\n",
    "        pc = convert_grid_to_pointcloud(vol)\n",
    "        if self.num_points is not None:\n",
    "            num_points = pc.shape[0]\n",
    "\n",
    "            if num_points < self.num_points:\n",
    "                pc = random_sample_arr(\n",
    "                    pc, count=self.num_points, replace=True)\n",
    "\n",
    "            else:\n",
    "                pc = random_sample_arr(pc, count=self.num_points)\n",
    "\n",
    "        return pc\n",
    "\n",
    "    def convert_volumetric_to_final(self, vol_example):\n",
    "\n",
    "        # final crop and relabel\n",
    "        vol_example = crop_where(vol_example, vol_example != 0)\n",
    "        vol_example = cc3d.connected_components(vol_example)\n",
    "\n",
    "        # sanity check\n",
    "        all_classes = np.unique(vol_example)\n",
    "        assert len(\n",
    "            all_classes) == 3, f'final sample should have 3 classes, [0, n1, n2] not {all_classes}'\n",
    "\n",
    "        # grid_volume(color.label2rgb(vol_example, bg_label=0))\n",
    "\n",
    "        # remove interiors\n",
    "        vol_example = self.remove_vol_interiors(vol_example)\n",
    "\n",
    "        # convert to point cloud\n",
    "        pc_example = self.convert_to_point_cloud(vol_example)\n",
    "        if self.Augmentor is not None:\n",
    "            pc_example = self.Augmentor.transfrom(pc_example)\n",
    "        pc_example = np.swapaxes(pc_example, 0, 1)\n",
    "\n",
    "        pc_example = torch.from_numpy(pc_example).type(torch.float32)\n",
    "\n",
    "        return pc_example\n",
    "\n",
    "    def get_drop_start_range(self):\n",
    "        # point at each drop end cannot exceede\n",
    "        cur_vol = self.get_cur_vol()\n",
    "        range_start = self.context_slices\n",
    "        range_stop = cur_vol.shape[0] - self.num_slices - self.context_slices\n",
    "\n",
    "\n",
    "        return (range_start, range_stop)\n",
    "\n",
    "    def increment_vol_and_drop(self):\n",
    "        if self.verbose:\n",
    "            print('increment drop')\n",
    "        self.cur_drop_start += 1\n",
    "        range_start, range_stop = self.get_drop_start_range()\n",
    "\n",
    "        # if we have reached the end of the vol, do to next vol\n",
    "        if self.cur_drop_start >= range_stop:\n",
    "            self.cur_vol_i += 1\n",
    "            self.cur_drop_start = range_start\n",
    "            if self.verbose:\n",
    "                print('increment vol')\n",
    "            if self.cur_vol_i >= len(self.vols):\n",
    "                raise StopIteration\n",
    "\n",
    "    def get_cur_vol(self):\n",
    "        return self.vols[self.cur_vol_i]\n",
    "\n",
    "    def get_cur_drop(self):\n",
    "        cur_drop_end = self.cur_drop_start + self.num_slices\n",
    "        return (self.cur_drop_start, cur_drop_end)\n",
    "\n",
    "    def get_next(self):\n",
    "        (examples, labels) = self.load_next_candidate_batch()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'vol: {self.cur_vol_i}, drop: {self.get_cur_drop()}, neurite: {self.cur_neurite_i}, candidate: {self.test_iteration_i}')\n",
    "\n",
    "        return (examples, labels)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            try:\n",
    "                yield self.get_next()\n",
    "            except StopIteration:\n",
    "                return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from proofreader.data.augment import Augmentor\n",
    "from proofreader.utils.torch import load_model\n",
    "from proofreader.model.config import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "config = get_config('cn_context_4_aug_small')\n",
    "\n",
    "model, _ ,_ = build_full_model_from_config(config.model, config.dataset)\n",
    "model = nn.DataParallel(model)\n",
    "model = load_model(model, '../../330.ckpt', map_location=torch.device('cpu'))\n",
    "\n",
    "num_slices = 4\n",
    "radius = 96\n",
    "context_slices = 4\n",
    "num_points = 1024\n",
    "augmentor = Augmentor(center=True, shuffle=True, normalize=[125, 1250, 1250])\n",
    "tester = TestDataset(test_vols[2:], num_slices, radius, context_slices, num_points=num_points, Augmentor=augmentor, verbose=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "dataloader = DataLoader(dataset=tester, batch_size=64)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    count, acc = 0,0\n",
    "    for step, batch in enumerate(tester):\n",
    "        count += 1\n",
    "        # get batch\n",
    "        x, y = batch\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            y_hat = model(x[i])\n",
    "            pred = predict_class(y_hat)\n",
    "            accs = get_accuracy(y, pred)\n",
    "            \n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.28125\n",
      "{'total_acc': 0.734375, 'true_acc': 0.8888888955116272, 'false_acc': 0.6739130616188049}\n",
      "0.734\n",
      "0.171875\n",
      "{'total_acc': 0.59375, 'true_acc': 0.9090909361839294, 'false_acc': 0.5283018946647644}\n",
      "0.664\n",
      "0.28125\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "lim = (-.1,.1)\n",
    "lim = (lim,lim,lim)\n",
    "for step, batch in enumerate(tester):\n",
    "    x, y = batch\n",
    "    print(step, y)\n",
    "    # for i in range(x.shape[0]):\n",
    "    #     pc = np.swapaxes(x[i], 0, 1)\n",
    "    #     label = y[i].item() == 1\n",
    "    #     plot_3d(pc, title=label, lims=lim)\n",
    "    if step > 50:\n",
    "        break\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0374b07a6c0abfb121bb99bd4abdfbae09652ed3c4472b09c61fe7de5eaf7be9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}