{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from proofreader.utils.io import read_cremi_volume, from_h5\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from proofreader.utils.plot import make_histogram\n",
    "\n",
    "def segmentation_size_hist(seg):\n",
    "    values, counts = np.unique(seg, return_counts=True)\n",
    "    num = len(values)\n",
    "    make_histogram(counts, bins=100, xlabel='Neuron Volume', title=f'{num} Total Neurons', logscale=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trueA = read_cremi_volume('A',seg=True, path='../../dataset/cremi')\n",
    "trueB = read_cremi_volume('B',seg=True, path='../../dataset/cremi')\n",
    "trueC = read_cremi_volume('C',seg=True, path='../../dataset/cremi')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imgA = read_cremi_volume('A', img=True, path='../../dataset/cremi')\n",
    "imgB = read_cremi_volume('B', img=True, path='../../dataset/cremi')\n",
    "imgC = read_cremi_volume('C', img=True, path='../../dataset/cremi')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predA = from_h5('../../dataset/segs/RSUnet_900000_seg_sample_A_pad.hdf', dataset_path='volumes/labels/neuron_ids')\n",
    "predB = from_h5('../../dataset/segs/RSUnet_900000_seg_sample_B_pad.hdf', dataset_path='volumes/labels/neuron_ids')\n",
    "predC = from_h5('../../dataset/segs/RSUnet_900000_seg_sample_C_pad.hdf', dataset_path='volumes/labels/neuron_ids')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from einops import rearrange\n",
    "import open3d as o3d \n",
    "\n",
    "def convert_3D_img_to_point_cloud(img, threshold=0, flip=True):\n",
    "\n",
    "    # flip zyx to xyz\n",
    "    if flip:\n",
    "        img = np.swapaxes(img,0,2)\n",
    "    \n",
    "    (sx, sy, sz) = img.shape\n",
    "    # generate all coords in img\n",
    "    cords =  np.mgrid[0:sx, 0:sy, 0:sx]\n",
    "    # select cords where above threshold\n",
    "    cords = cords[:][img > threshold]\n",
    "    cords =  rearrange(cords, 'xyz x y z -> xyz (x y z)')\n",
    "\n",
    "    return cords\n",
    "\n",
    "def numpy_to_pointcloud(arr, colors=None):\n",
    "    arr = arr.astype('float64')\n",
    "    colors = colors.astype('float64')\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(arr)\n",
    "    if colors is not None:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def get_pointcloud(img, masks, resolution=(1, 1, 10), paint=False):\n",
    "    pcds = []\n",
    "    for mask in masks:\n",
    "        (sz, sy, sx) = img.shape\n",
    "        cords =  np.mgrid[0:sz, 0:sy, 0:sx]\n",
    "        pc = cords[:, mask]\n",
    "        pc = np.swapaxes(pc,0,1)\n",
    "        cm = img[mask] / 255\n",
    "        colors = np.swapaxes(np.vstack((cm,cm,cm)),0,1)\n",
    "        pcd = numpy_to_pointcloud(pc, colors=colors)\n",
    "        if paint:\n",
    "            pcd.paint_uniform_color(np.random.rand((3)))\n",
    "        pcds.append(pcd)\n",
    "\n",
    "    return pcds\n",
    "    # # fit to unit cube\n",
    "    # pcd.scale(1 / np.max(pcd.get_max_bound() - pcd.get_min_bound()),\n",
    "    #         center=pcd.get_center())\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classes = get_classes_sorted_by_volume(trueB, reverse=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "neurites = []\n",
    "for i in range(4):  \n",
    "    n = get_pointcloud(imgB, [trueB==classes[50+i]], paint=False)\n",
    "    neurites.append(n)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nur = neurites[0]\n",
    "for n in neurites:\n",
    "    nur += n\n",
    "o3d.visualization.draw_geometries(nur)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# try to find merger/splitters\n",
    "\n",
    "trueA = read_cremi_volume('A',seg=True, path='../../dataset/cremi')\n",
    "trueB = read_cremi_volume('B',seg=True, path='../../dataset/cremi')\n",
    "trueC = read_cremi_volume('C',seg=True, path='../../dataset/cremi')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predA = from_h5('../../dataset/segs/RSUnet_900000_seg_sample_A_pad.hdf', dataset_path='volumes/labels/neuron_ids')\n",
    "predB = from_h5('../../dataset/segs/RSUnet_900000_seg_sample_B_pad.hdf', dataset_path='volumes/labels/neuron_ids')\n",
    "predC = from_h5('../../dataset/segs/RSUnet_900000_seg_sample_C_pad.hdf', dataset_path='volumes/labels/neuron_ids')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_classes_sorted_by_volume(vol, reverse=False, return_counts=False):\n",
    "\n",
    "    classes, counts = np.unique(vol, return_counts=True)\n",
    "\n",
    "    sort_indices = np.argsort(counts)\n",
    "    if reverse:\n",
    "        sort_indices = np.flip(sort_indices)\n",
    "    classes = classes[sort_indices]\n",
    "    if return_counts:\n",
    "        counts = counts[sort_indices]\n",
    "        return classes, counts\n",
    "    return classes\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_coverage_over_threshold(true, pred, c, threshold):\n",
    "    overlap = pred[true == c]\n",
    "    classes, counts = get_classes_sorted_by_volume(overlap, return_counts=True)\n",
    "    vol = np.sum(counts)\n",
    "    percents = np.round(counts / vol, 2)\n",
    "    truncated_percents = []\n",
    "    truncated_classes = []\n",
    "    for i in reversed(range(len(percents))):\n",
    "        if percents[i] > threshold:\n",
    "            truncated_percents.append(percents[i])\n",
    "            truncated_classes.append(classes[i])\n",
    "        else:\n",
    "            return np.array(truncated_classes), np.array(truncated_percents)\n",
    "    return [], []\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from proofreader.utils.plot import make_histogram\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def print_coverage_stats(c, classes, percents, true_base):\n",
    "    if true_base:\n",
    "        base = 'true'\n",
    "        not_base = 'pred'\n",
    "    else:\n",
    "        base = 'pred'\n",
    "        not_base = 'true'\n",
    "    for i in range(len(percents)):\n",
    "        print(f'{classes[i]} in {not_base} covers {percents[i]*100}% of {c} in {base}')\n",
    "\n",
    "def get_coverage_recursive(A, B, c, threshold=.1, seen=[], true_base=True, depth=0, max_depth=5, final_depth=-1, verbose=True):\n",
    "    seen.append(c)\n",
    "    classes0, percents0 = get_coverage_over_threshold(A, B, c, threshold)\n",
    "    if len(percents0) > 1:\n",
    "        if verbose:\n",
    "            print(f'DEPTH: {depth}')\n",
    "            print_coverage_stats(c, classes0, percents0, true_base)\n",
    "        final_depth = depth\n",
    "        if depth < max_depth:\n",
    "            for c0 in classes0:\n",
    "                    final_depth = max(get_coverage_recursive(B, A, c0, threshold=threshold, seen=seen, true_base=not true_base, depth=depth+1, max_depth=max_depth, verbose=verbose), final_depth)\n",
    "\n",
    "    return final_depth \n",
    "\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_order_0_splitters(true, pred):\n",
    "    classes = get_classes_sorted_by_volume(true)\n",
    "    order_0_splitters = {}\n",
    "    for c in classes[-200:]:\n",
    "        final_depth = get_coverage_recursive(true, pred, c, seen=[], max_depth=1, verbose=False)\n",
    "        if final_depth == 0:\n",
    "            classes0, _ = get_coverage_over_threshold(true, pred, c, 0.1)\n",
    "            order_0_splitters[c] = classes0\n",
    "    return order_0_splitters\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from proofreader.utils.io import from_h5\n",
    "\n",
    "path = '/mnt/home/jberman/sc/proofreader/dataset/CREMI/corrected/seg_A.h5'\n",
    "seg_A = from_h5(path)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path = '/mnt/home/jberman/sc/proofreader/dataset/CREMI/corrected/syn_A.h5'\n",
    "syn_A = from_h5(path)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path = '/mnt/home/jberman/sc/proofreader/dataset/CREMI/corrected/im_A.h5'\n",
    "im_A = from_h5(path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "syn_A.shape"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0374b07a6c0abfb121bb99bd4abdfbae09652ed3c4472b09c61fe7de5eaf7be9"
  },
  "kernelspec": {
   "name": "python388jvsc74a57bd00374b07a6c0abfb121bb99bd4abdfbae09652ed3c4472b09c61fe7de5eaf7be9",
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}